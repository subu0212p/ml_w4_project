{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d6ceb9d"
      },
      "source": [
        "## 1. Install & Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Q2PGnLChnT-F"
      },
      "outputs": [],
      "source": [
        "# Install required libraries and import necessary modules\n",
        "!pip install transformers datasets\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from datasets import load_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "326bb751"
      },
      "source": [
        "## 2. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6iYvco4tocPT"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer and Mahatma Gandhi text dataset\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Load your text file\n",
        "with open('MahatmaGandhi.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28819b88"
      },
      "source": [
        "## 3. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DkGulJg7tC2P"
      },
      "outputs": [],
      "source": [
        "# Set up model, custom dataset class, and data collator\n",
        "from transformers import GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Define a custom dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.input_ids = encodings['input_ids']\n",
        "        self.attn_masks = encodings['attention_mask']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attn_masks[idx],\n",
        "            'labels': self.input_ids[idx]\n",
        "        }\n",
        "\n",
        "# Load the model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Prepare dataset\n",
        "dataset = TextDataset(tokens)\n",
        "\n",
        "# Data collator for language modeling\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60afe839"
      },
      "source": [
        "## 4. Model & Dataset Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WPK4KRtztmeH"
      },
      "outputs": [],
      "source": [
        "# Define training arguments and start model fine-tuning\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",          # Where to save model\n",
        "    overwrite_output_dir=True,       # Overwrite previous results\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,   # Small batch for quick training\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=1,\n",
        "    logging_steps=100,\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba8c9017"
      },
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWL8GcnMz2vd"
      },
      "outputs": [],
      "source": [
        "# Generate text using the trained model based on a prompt\n",
        "prompt = \"Mahatma Gandhi believed in\"\n",
        "\n",
        "output = model.generate(\n",
        "    **tokenizer(prompt, return_tensors='pt'),\n",
        "    max_length=60,\n",
        "    num_return_sequences=1,\n",
        "    do_sample=True,               # Enable randomness\n",
        "    top_k=50,                     # Sample from top 50 tokens\n",
        "    top_p=0.95,                   # Nucleus sampling\n",
        "    temperature=0.9               # Add more creativity\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ddc6589"
      },
      "source": [
        "## 6. Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "a7NnEQUy2t0F"
      },
      "outputs": [],
      "source": [
        "# Evaluate model performance using perplexity\n",
        "model.save_pretrained(\"./gandhi_nextword_model\")\n",
        "tokenizer.save_pretrained(\"./gandhi_nextword_model\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78bb7338"
      },
      "source": [
        "## 7. Evaluation - Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVwr-ZxH22KU"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "\n",
        "def calculate_perplexity(model, tokenizer, text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, labels=input_ids)\n",
        "        loss = outputs.loss\n",
        "    return math.exp(loss.item())\n",
        "\n",
        "# Example\n",
        "model.eval()\n",
        "perplexity = calculate_perplexity(model, tokenizer, \"Mahatma Gandhi was known for\")\n",
        "print(f\"Perplexity: {perplexity:.2f}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}